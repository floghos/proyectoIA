{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504658b2",
   "metadata": {},
   "source": [
    "# Samurai Gunn map tile classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4e8bb",
   "metadata": {},
   "source": [
    "#### First we define the window capture function\n",
    "On it's own, it seems to barely have any performance cost, outputting up to 800-900 fps when capturing the windowed version of Samurai Gunn, a 320x240 px window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8507dbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       [[  0,   0,   0, 255],\n",
       "        [ 90,  74,  21, 255],\n",
       "        [ 90,  74,  21, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       [[  0,   0,   0, 255],\n",
       "        [ 90,  74,  21, 255],\n",
       "        [ 90,  74,  21, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       [[  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]],\n",
       "\n",
       "       [[  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        ...,\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255],\n",
       "        [  0,   0,   0, 255]]], dtype=uint8)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from time import time\n",
    "import win32gui\n",
    "import win32ui\n",
    "import win32con\n",
    "\n",
    "def list_all_open_windows():\n",
    "    '''Lists the names and handles of all opened windows\n",
    "    '''\n",
    "    def winEnumHandler( hwnd, ctx ):\n",
    "        if win32gui.IsWindowVisible( hwnd ):\n",
    "            print (hex(hwnd), win32gui.GetWindowText( hwnd ))\n",
    "\n",
    "    win32gui.EnumWindows(winEnumHandler, None)\n",
    "\n",
    "#list_all_open_windows()\n",
    "\n",
    "def window_capture():\n",
    "    hwnd = win32gui.FindWindow(None, 'Samurai Gunn')\n",
    "    \n",
    "    # Getting the window's size and accounting for window screenshot borders\n",
    "    # does not work consistently?\n",
    "    #window_rect = win32gui.GetWindowRect(hwnd)\n",
    "    \n",
    "    # para notebook de Pablo\n",
    "    #     titlebar_px = 38\n",
    "    #     border_px = 9\n",
    "    titlebar_px = 38\n",
    "    border_px = 9\n",
    "\n",
    "    # For samurai Gunn, the non-fullscreen dimensions should be:\n",
    "    w = 320\n",
    "    h = 240\n",
    "    \n",
    "    crop_x = border_px\n",
    "    crop_y = titlebar_px\n",
    "    \n",
    "    wDC = win32gui.GetWindowDC(hwnd)\n",
    "    dcObj = win32ui.CreateDCFromHandle(wDC)\n",
    "    cDC = dcObj.CreateCompatibleDC()\n",
    "    dataBitMap = win32ui.CreateBitmap()\n",
    "    dataBitMap.CreateCompatibleBitmap(dcObj, w, h)\n",
    "    cDC.SelectObject(dataBitMap)\n",
    "    cDC.BitBlt((0, 0), (w, h) , dcObj, (crop_x, crop_y), win32con.SRCCOPY)\n",
    "    \n",
    "    # To save screenshot to file, uncomment the 2 lines below \n",
    "#     bmpfilenamename = \"sample\" + str(img_counter) + \".jpg\" #set this\n",
    "    bmpfilenamename = \"splinter_samples2.jpg\" #set this\n",
    "    dataBitMap.SaveBitmapFile(cDC, bmpfilenamename)\n",
    "    \n",
    "    # Converting to format useful for opencv\n",
    "    signedIntsArray = dataBitMap.GetBitmapBits(True)\n",
    "    img = np.frombuffer(signedIntsArray, dtype='uint8')\n",
    "    img.shape = (h, w, 4)\n",
    "\n",
    "    # Free Resources\n",
    "    dcObj.DeleteDC()\n",
    "    cDC.DeleteDC()\n",
    "    win32gui.ReleaseDC(hwnd, wDC)\n",
    "    win32gui.DeleteObject(dataBitMap.GetHandle())\n",
    "    \n",
    "    \n",
    "    # Dropping alpha channel may be useful for some applications, like cv.matchTemplate()\n",
    "    # which may throw an error otherwise\n",
    "    \n",
    "    #img = img[...,:3]   # this drops alpha channel \n",
    "    \n",
    "    return img\n",
    "\n",
    "window_capture()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae2276",
   "metadata": {},
   "source": [
    "## Defining Tile classification functions\n",
    "We can notice that each map tile sits in a grid of 15x20 tiles, with each tile being (16x16)px, with some exceptions that are offset vertically by half a tile.\n",
    "Taking advantage of this, we can simplify the input given to our neural network by reducing each tile to a single pixel that represents the contents of it (e.g.: ground, empty, player, spike...)\n",
    "\n",
    "It's important to note that even if the map tiles can only ever be on this discrete grid, the players are free to move in the full continuous plane. This must be taken into consideration when classifying tiles that contain players.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304e3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_step = 2\n",
    "col_step = 2\n",
    "def classify_tile(x, y, img, sliced):\n",
    "    '''\n",
    "    Tiles are (16 x 16)px\n",
    "    Parameters:\n",
    "    x, y  : coords of the upper left corner of the tile\n",
    "    img: input image\n",
    "    sliced: int, either 0 or 1, letting us know if it's a full tile or a half tile at the \n",
    "             upper/lower edges of the map. \n",
    "             0 means it's a full tile\n",
    "             1 means it's a half tile\n",
    "    Returns:\n",
    "    int: Returns a single int that will classify the tile\n",
    "    '''\n",
    "    px_count = 0\n",
    "    total = np.zeros((1, img.shape[2]), dtype='uint32')\n",
    "    \n",
    "    corrected_height_range = int(16/(1+sliced))\n",
    "    for i in range(0, corrected_height_range, row_step):\n",
    "        for j in range(0, 16, col_step):\n",
    "            total += img[x+i][y+j] # [b, g, r, a]\n",
    "            px_count += 1           \n",
    "    \n",
    "    #result = result.astype('uint8') \n",
    "    # for some reason this doesn't work. It's fine tho, it works if\n",
    "    # we convert the data type before returning on the simplify() funct\n",
    "    result = total * ((1+sliced)/(px_count))\n",
    "    result = result[:3]\n",
    "    \n",
    "    return result  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a7bf0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_mask(img):\n",
    "    mask = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    size = mask.shape\n",
    "    for i in range(size[0]):\n",
    "        for j in range(size[1]):\n",
    "            if mask[i][j] < 70 or mask[i][j] > 230:\n",
    "                mask[i][j] = 1\n",
    "            elif mask[i][j] > 100 and mask[i][j] < 190:\n",
    "                mask[i][j] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e2a7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simplify(img, offset, mask = None):\n",
    "    '''Reduces the input image resolution by classifying the tiles on the screen and \n",
    "    reducing them to 1 px per tile.\n",
    "    The tiles in every map can be aligned with a 20 x 15 grid of (16 x 16)px cells.\n",
    "    Iterates over each tile, calling classify_tile() for each of them\n",
    "    \n",
    "    Parameters:\n",
    "    img: input image\n",
    "    offset: in case the map tiles do not align perfectly with the grid, an offset of 8px down does \n",
    "            the trick. (Maps with different offsets have yet to be found, \n",
    "            this should allow for different offsets in the X direction)\n",
    "            \n",
    "    Returns:\n",
    "    numpy 3D array: (15 x 20 x num_channels) numpy array\n",
    "    '''\n",
    "    sliced = 0\n",
    "    simple_img = np.zeros((15, 20, img.shape[2]))    \n",
    "\n",
    "    for x in range(15):\n",
    "        if offset == 8 and (x == 0 or x == 19):\n",
    "            sliced = 1\n",
    "        else:\n",
    "            sliced = 0\n",
    "        for y in range(20):\n",
    "            # pass the coordinates of each tile with corrections to accomodate for the grid offset\n",
    "            if mask is None or mask[x][y] == 0:\n",
    "                simple_img[x, y] = classify_tile_2(x*16 - (offset*(1-sliced)), \n",
    "                                                   y*16 - (offset*(1-sliced)), \n",
    "                                                   img, sliced)\n",
    "    simple_img = simple_img.astype('uint8')\n",
    "    return simple_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e37e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_2(img, offset, mask = None):\n",
    "    sliced = 0\n",
    "    simple_img = np.zeros((15, 20, 3))    \n",
    "\n",
    "    for x in range(15):\n",
    "        if offset == 8 and (x == 0 or x == 19):\n",
    "            sliced = 1\n",
    "        else:\n",
    "            sliced = 0\n",
    "        for y in range(20):\n",
    "            # pass the coordinates of each tile with corrections to accomodate for the grid offset\n",
    "            if mask is None:\n",
    "                simple_img[x, y] = classify_tile_2(x*16 - (offset*(1-sliced)), \n",
    "                                                   y*16 - (offset*(1-sliced)), \n",
    "                                                   img, sliced)\n",
    "                continue\n",
    "            if mask[x][y] == 0:\n",
    "                simple_img[x, y] = find_players(x*16 - (offset*(1-sliced)), \n",
    "                                                   y*16 - (offset*(1-sliced)), \n",
    "                                                   img, sliced)\n",
    "    simple_img = simple_img.astype('uint8')\n",
    "    return simple_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df81d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tile_2(x, y, img, sliced):\n",
    "    # clasifica segun la moda.\n",
    "    # parece funcionar bien para mapear plataformas\n",
    "    row_step = 2\n",
    "    col_step = 1\n",
    "    freq = {}\n",
    "    \n",
    "    corrected_height_range = int(16/(1+sliced))\n",
    "    for i in range(0, corrected_height_range, row_step):\n",
    "        for j in range(0, 16, col_step):\n",
    "            c = img[x+i][y+j]  \n",
    "            c_aux = (c[0], c[1], c[2]) # change the color array into a hashable tuple\n",
    "            if freq.get(c_aux) == None:\n",
    "                freq[c_aux] = 1\n",
    "            else:\n",
    "                freq[c_aux] += 1\n",
    "\n",
    "    values = list(freq.values())\n",
    "    m = 0\n",
    "    index = 0\n",
    "    for i in range(len(values)):\n",
    "        if values[i] > m:\n",
    "            m = values[i]\n",
    "            index = i\n",
    "    \n",
    "    keys = list(freq.keys())\n",
    "    result = keys[index]\n",
    "#     if img.shape[2] == 4:\n",
    "#         result = (result[0], result[1], result[2], 255)\n",
    "    #result = total * ((1+sliced)/(px_count))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49aa259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_temp_r = cv.imread(\"char_templates/splinter_needle_r.jpg\")\n",
    "player_temp_l = cv.imread(\"char_templates/splinter_needle_l.jpg\")\n",
    "enemy_temp = cv.imread(\"char_templates/ninja_needle.jpg\")\n",
    "\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "           'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "\n",
    "# \"player key color\" this is a distinctive color for the rat-like player\n",
    "# funciona en BGR (???)\n",
    "pkc = (65, 191, 97)\n",
    "\n",
    "# \"enemy key color\" this is a distinctive color for the ninja enemy bot in survival mode\n",
    "ekc = (11, 11, 13)\n",
    "\n",
    "\n",
    "def find_players(x, y, img, sliced):\n",
    "    \n",
    "    row_step = 2\n",
    "    col_step = 2   \n",
    "    tile = np.zeros((16, 16, 3), dtype='uint8')\n",
    "    \n",
    "    p_threshold = 0.6\n",
    "    e_threshold = 0.312\n",
    "    \n",
    "    player_flag = False\n",
    "    enemy_flag = False\n",
    "    corrected_height_range = int(16/(1+sliced))\n",
    "    for i in range(0, corrected_height_range, row_step):\n",
    "        for j in range(0, 16, col_step):\n",
    "            aux = img[x+i][y+j][:3]\n",
    "            if tuple(aux) == pkc:\n",
    "                player_flag = True\n",
    "                #print('player flag set')\n",
    "            if tuple(aux) == ekc:\n",
    "                enemy_flag = True\n",
    "                #print('enemy flag set')\n",
    "                \n",
    "    if player_flag or enemy_flag:\n",
    "        for i in range(0, corrected_height_range):\n",
    "            for j in range(0, 16):\n",
    "                tile[i][j] = img[x+i][y+j][:3]\n",
    "            \n",
    "                \n",
    "    min_val_p, max_val_p, min_loc_p, max_loc_p = (0, 0, (0,0), (0,0))\n",
    "    min_val_e, max_val_e, min_loc_e, max_loc_e = (0, 0, (0,0), (0,0))\n",
    "    \n",
    "    if player_flag:\n",
    "        search_p1 = cv.matchTemplate(tile, player_temp_r, cv.TM_CCOEFF_NORMED)\n",
    "        min_val_p1, max_val_p1, min_loc_p, max_loc_p = cv.minMaxLoc(search_p1)\n",
    "        \n",
    "        search_p2 = cv.matchTemplate(tile, player_temp_l, cv.TM_CCOEFF_NORMED)\n",
    "        min_val_p2, max_val_p2, min_loc_p, max_loc_p = cv.minMaxLoc(search_p2)\n",
    "        \n",
    "        max_val_p = max_val_p1 if (max_val_p1 > max_val_p2) else max_val_p2\n",
    "#         min_val_p = min_val_p1 if (min_val_p1 < min_val_p2) else min_val_p2\n",
    "#         print('max_val for player {}'.format(max_val_p))\n",
    "    \n",
    "    if enemy_flag:\n",
    "        search_e = cv.matchTemplate(tile, enemy_temp, cv.TM_CCOEFF_NORMED)\n",
    "        min_val_e, max_val_e, min_loc_e, max_loc_e = cv.minMaxLoc(search_e)\n",
    "#         print('max_val for enemy {}'.format(max_val_e))\n",
    "\n",
    "    result = np.zeros(3)\n",
    "    if max_val_p > p_threshold and max_val_e < e_threshold:\n",
    "        return pkc\n",
    "    elif max_val_p < p_threshold and max_val_e > e_threshold:\n",
    "        #return ekc\n",
    "        return (0, 0, 255)\n",
    "    elif max_val_p > p_threshold and max_val_e > e_threshold:\n",
    "        avg = np.zeros(3, dtype='uint8')\n",
    "        for i in range(3):\n",
    "            avg[i] = (pkc[i] + ekc[i]) / 2\n",
    "        return tuple(avg)\n",
    "    else:\n",
    "        return (255, 255, 255)\n",
    "        \n",
    "#     if img.shape[2] == 4:\n",
    "#         # this means the resulting img should have an alpha channel\n",
    "#         result = (result[0], result[1], result[2], 255)\n",
    "    \n",
    "    #return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c98ef9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport cv2 as cv\\nmethods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\\n           'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\\n\\nimg = cv.imread('char_templates/ninja_temp_1.jpg')\\nneedle = cv.imread('char_templates/ninja_temp_l.jpg')\\n\\nres = cv.matchTemplate(img, needle, cv.TM_SQDIFF_NORMED)\\n\\nmin_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\\n\\nprint(min_loc)\\n\\nprint(min_val, max_val)\\ncv.imshow('res',res)\\nif cv.waitKey(0) & 0xFF == ord('q'):\\n        cv.destroyAllWindows()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import cv2 as cv\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "           'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "\n",
    "img = cv.imread('char_templates/ninja_temp_1.jpg')\n",
    "needle = cv.imread('char_templates/ninja_temp_l.jpg')\n",
    "\n",
    "res = cv.matchTemplate(img, needle, cv.TM_SQDIFF_NORMED)\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "\n",
    "print(min_loc)\n",
    "\n",
    "print(min_val, max_val)\n",
    "cv.imshow('res',res)\n",
    "if cv.waitKey(0) & 0xFF == ord('q'):\n",
    "        cv.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1746d2",
   "metadata": {},
   "source": [
    "## Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8165174f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg FPS 23.794143584733053\n",
      "Avg FPS 22.48088093480026\n",
      "Avg FPS 21.992718194426814\n"
     ]
    }
   ],
   "source": [
    "frame_count = 1\n",
    "cumulative_fps = 0\n",
    "ss_counter = 0  # \"screenshot counter\"\n",
    "\n",
    "# offset will depend on the map\n",
    "# for Ice cube, offset is 0\n",
    "offset = 0\n",
    "mk = None\n",
    "while(True):\n",
    "    prev_time = time()\n",
    "    \n",
    "    screenshot = window_capture()\n",
    "    #screenshot = cv.imread('sample0.jpg')\n",
    "    \n",
    "    img = simplify_2(screenshot, offset, mask=mk)\n",
    "    \n",
    "    # re-calculate mask every so often\n",
    "    if frame_count % 128 == 0: \n",
    "        mk = map_mask(simplify_2(screenshot, offset))\n",
    "    \n",
    "    dim = (img.shape[1] * 16, img.shape[0] * 16)\n",
    "    resized = cv.resize(img, dim, interpolation = cv.INTER_AREA) #  interpolation = cv.INTER_AREA\n",
    "\n",
    "    cv.imshow('Simplified', resized)\n",
    "    #cv.imshow('Screenshot', screenshot)\n",
    "    #print('FPS {}'.format(1 / (time() - prev_time)))\n",
    "    \n",
    "    delta_time = time() - prev_time\n",
    "    if delta_time == 0:\n",
    "        delta_time = 1\n",
    "        \n",
    "    cumulative_fps += 1 / delta_time\n",
    "    if frame_count % 128 == 0:\n",
    "        print('Avg FPS {}'.format(cumulative_fps/frame_count))\n",
    "    frame_count += 1\n",
    "    \n",
    "    if frame_count % 512 == 0:\n",
    "        frame_count = 1\n",
    "        cumulative_fps = 0\n",
    "    \n",
    "        \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv.destroyAllWindows()\n",
    "        break\n",
    "#     elif cv.waitKey(1) & 0xFF == ord('p'):\n",
    "#         cv.imwrite('simplified_img_{}.jpg'.format(ss_counter), img)\n",
    "#         ss_counter += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
